{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stocks Forecasting — Train + Predict + Plot\n",
        "\n",
        "This notebook:\n",
        "1. Loads a `stocks-forecasting` config\n",
        "2. Trains a TFT model (Darts)\n",
        "3. Loads the saved bundle\n",
        "4. Produces log-return quantile forecasts for a selected symbol\n",
        "5. Back-transforms to price-path quantiles and plots historical close + forecast band\n",
        "\n",
        "Prereqs:\n",
        "- The `stocks` harness Postgres is running on `localhost:5432`\n",
        "- You are using the `repos/stocks-forecasting/.venv` kernel (or any env with `stocks-forecasting` installed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    for p in [start, *start.parents]:\n",
        "        if (p / \"pyproject.toml\").exists():\n",
        "            return p\n",
        "    raise RuntimeError(\"Could not find repo root (missing pyproject.toml)\")\n",
        "\n",
        "\n",
        "ROOT = find_repo_root(Path.cwd())\n",
        "print(\"Repo root:\", ROOT)\n",
        "\n",
        "# Local cache dirs (avoid writing to ~)\n",
        "os.environ.setdefault(\"XDG_CACHE_HOME\", str(ROOT / \".cache\"))\n",
        "os.environ.setdefault(\"MPLCONFIGDIR\", str(ROOT / \".mplconfig\"))\n",
        "os.environ.setdefault(\"TORCH_HOME\", str(ROOT / \".torch\"))\n",
        "\n",
        "Path(os.environ[\"XDG_CACHE_HOME\"]).mkdir(parents=True, exist_ok=True)\n",
        "Path(os.environ[\"MPLCONFIGDIR\"]).mkdir(parents=True, exist_ok=True)\n",
        "Path(os.environ[\"TORCH_HOME\"]).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# DB password for local docker-compose (override in your environment if different)\n",
        "os.environ.setdefault(\"POSTGRES_PASSWORD\", \"postgres\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stocks_forecasting.config.load import load_config\n",
        "from stocks_forecasting.config.models import RunMode\n",
        "\n",
        "CONFIG_PATH = ROOT / \"configs\" / \"config.smoke.yaml\"\n",
        "config = load_config(CONFIG_PATH)\n",
        "\n",
        "# Recommended for \"serving-like\" training runs:\n",
        "# config.project.mode = RunMode.production\n",
        "\n",
        "config.model_dump()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stocks_forecasting.artifacts import create_bundle_paths\n",
        "from stocks_forecasting.training.train_tft import train_tft\n",
        "\n",
        "RUN_TRAINING = True\n",
        "\n",
        "if RUN_TRAINING:\n",
        "    bundle_paths = train_tft(config, artifacts_root=ROOT / config.artifacts.root_dir)\n",
        "else:\n",
        "    bundle_root = ROOT / config.artifacts.root_dir / config.artifacts.bundle_name\n",
        "    versions = sorted([p.name for p in bundle_root.iterdir() if p.is_dir()])\n",
        "    if not versions:\n",
        "        raise RuntimeError(f\"No bundles found under {bundle_root}\")\n",
        "    bundle_paths = create_bundle_paths(\n",
        "        root_dir=ROOT / config.artifacts.root_dir,\n",
        "        bundle_name=config.artifacts.bundle_name,\n",
        "        version=versions[-1],\n",
        "    )\n",
        "\n",
        "print(\"Bundle root:\", bundle_paths.root)\n",
        "bundle_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "manifest = json.loads(bundle_paths.manifest_path.read_text())\n",
        "manifest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from darts.models import TFTModel\n",
        "\n",
        "model_path = bundle_paths.model_dir / \"tft_model.pt\"\n",
        "model = TFTModel.load(str(model_path))\n",
        "\n",
        "print(\"Loaded model:\", model.__class__.__name__)\n",
        "print(\"Model path:\", model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from darts import TimeSeries\n",
        "\n",
        "from stocks_forecasting.calendars import build_trading_calendar\n",
        "from stocks_forecasting.dataset.metadata import add_market_cap_bucket\n",
        "from stocks_forecasting.dataset.prepare_symbol import build_symbol_feature_frame\n",
        "from stocks_forecasting.db import PostgresClient\n",
        "\n",
        "SYMBOL = \"AAPL\"\n",
        "PLOT_HISTORY_POINTS = 300\n",
        "NUM_SAMPLES = 500\n",
        "\n",
        "client = PostgresClient(config.database)\n",
        "\n",
        "meta = client.fetch_stock_metadata(symbols=[SYMBOL])\n",
        "if meta.empty:\n",
        "    raise ValueError(f\"Unknown symbol or missing metadata: {SYMBOL}\")\n",
        "meta = add_market_cap_bucket(meta)\n",
        "\n",
        "exchange_mic = None\n",
        "if pd.notna(meta.loc[0, \"exchange_mic\"]):\n",
        "    exchange_mic = str(meta.loc[0, \"exchange_mic\"])\n",
        "\n",
        "calendar = build_trading_calendar(config.features.calendar, exchange_mic=exchange_mic)\n",
        "\n",
        "summary = client.fetch_price_summary(SYMBOL, price_type=config.data.price_type)\n",
        "as_of_date = pd.to_datetime(summary.end_time, utc=True).normalize()\n",
        "print(\"as_of_date:\", as_of_date.date(), \"rows:\", summary.rows)\n",
        "\n",
        "prices = client.fetch_daily_prices(SYMBOL, price_type=config.data.price_type, end_time=as_of_date.to_pydatetime())\n",
        "prices[\"time\"] = pd.to_datetime(prices[\"time\"], utc=True).dt.normalize()\n",
        "prices = (\n",
        "    prices.dropna(subset=[\"time\"])  # defensive\n",
        "    .sort_values(\"time\")\n",
        "    .drop_duplicates(\"time\", keep=\"last\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "origin_time = prices[\"time\"].iloc[-1]\n",
        "origin_close = float(prices[\"close\"].iloc[-1])\n",
        "\n",
        "built = build_symbol_feature_frame(prices, config, calendar=calendar)\n",
        "frame = built.frame.sort_values(\"time\").reset_index(drop=True)\n",
        "frame[\"step\"] = np.arange(len(frame), dtype=\"int32\")\n",
        "\n",
        "observed = frame[frame[\"is_future\"] == 0].copy()\n",
        "required = [\"log_return\", *built.past_covariate_columns]\n",
        "observed = observed.dropna(subset=required)\n",
        "\n",
        "target_df = observed[[\"step\", \"log_return\"]]\n",
        "past_cov_df = observed[[\"step\", *built.past_covariate_columns]] if built.past_covariate_columns else None\n",
        "future_cov_df = frame[[\"step\", *built.future_covariate_columns]] if built.future_covariate_columns else None\n",
        "\n",
        "target_ts = TimeSeries.from_dataframe(target_df, time_col=\"step\", value_cols=[\"log_return\"]).astype(np.float32)\n",
        "past_cov_ts = (\n",
        "    TimeSeries.from_dataframe(past_cov_df, time_col=\"step\", value_cols=built.past_covariate_columns).astype(np.float32)\n",
        "    if past_cov_df is not None\n",
        "    else None\n",
        ")\n",
        "future_cov_ts = (\n",
        "    TimeSeries.from_dataframe(future_cov_df, time_col=\"step\", value_cols=built.future_covariate_columns).astype(np.float32)\n",
        "    if future_cov_df is not None\n",
        "    else None\n",
        ")\n",
        "\n",
        "# Attach static covariates aligned to training dummy columns (if present)\n",
        "static_cols = [\"exchange_mic\", \"sector\", \"industry\", \"country_code\", \"currency\", \"market_cap_bucket\"]\n",
        "row = meta.loc[0, static_cols].fillna(\"unknown\").astype(str)\n",
        "static_row_df = pd.DataFrame([{c: row[c] for c in static_cols}])\n",
        "static_dum = pd.get_dummies(static_row_df[static_cols], prefix=static_cols, dtype=\"int8\")\n",
        "\n",
        "trained_static_cols = manifest.get(\"features\", {}).get(\"static_covariates\", []) or []\n",
        "if trained_static_cols:\n",
        "    static_dum = static_dum.reindex(columns=trained_static_cols, fill_value=0)\n",
        "    target_ts = target_ts.with_static_covariates(static_dum)\n",
        "    if past_cov_ts is not None:\n",
        "        past_cov_ts = past_cov_ts.with_static_covariates(static_dum)\n",
        "    if future_cov_ts is not None:\n",
        "        future_cov_ts = future_cov_ts.with_static_covariates(static_dum)\n",
        "\n",
        "print(\"Prepared observed points:\", len(target_ts))\n",
        "print(\"Past covariates:\", past_cov_ts is not None, \"Future covariates:\", future_cov_ts is not None)\n",
        "print(\"Origin:\", origin_time.date(), \"close=\", origin_close)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def timeseries_to_frame(ts, index_name: str = \"step\") -> pd.DataFrame:\n",
        "    df = ts.to_dataframe()\n",
        "    out = df.reset_index()\n",
        "    out = out.rename(columns={out.columns[0]: index_name})\n",
        "    return out\n",
        "\n",
        "\n",
        "def forecast_to_quantile_frame(forecast, quantiles: list[float], index_name: str = \"step\") -> pd.DataFrame:\n",
        "    out = None\n",
        "    for q in quantiles:\n",
        "        q_ts = forecast.quantile(q)\n",
        "        q_df = timeseries_to_frame(q_ts, index_name=index_name)\n",
        "        value_cols = [c for c in q_df.columns if c != index_name]\n",
        "        if len(value_cols) != 1:\n",
        "            raise ValueError(\"Expected a single component when extracting quantiles\")\n",
        "        q_df = q_df.rename(columns={value_cols[0]: f\"q{q:g}\"})\n",
        "        out = q_df if out is None else out.merge(q_df, on=index_name, how=\"inner\")\n",
        "\n",
        "    if out is None or out.empty:\n",
        "        raise ValueError(\"No quantiles extracted\")\n",
        "    out = out.sort_values(index_name).reset_index(drop=True)\n",
        "    out[\"horizon_step\"] = np.arange(1, len(out) + 1, dtype=\"int32\")\n",
        "    return out\n",
        "\n",
        "\n",
        "horizon = int(config.model.horizon_days)\n",
        "quantiles = [float(q) for q in config.model.quantiles]\n",
        "\n",
        "forecast = model.predict(\n",
        "    n=horizon,\n",
        "    series=target_ts,\n",
        "    past_covariates=past_cov_ts,\n",
        "    future_covariates=future_cov_ts,\n",
        "    num_samples=NUM_SAMPLES,\n",
        ")\n",
        "\n",
        "pred_lr = forecast_to_quantile_frame(forecast, quantiles, index_name=\"step\")\n",
        "pred_lr = pred_lr.merge(frame[[\"step\", \"time\", \"is_future\"]], on=\"step\", how=\"left\")\n",
        "pred_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Back-transform log-return quantiles -> price-path quantiles\n",
        "pred_prices = pd.DataFrame({\"time\": pd.to_datetime(pred_lr[\"time\"], utc=True)})\n",
        "for q in quantiles:\n",
        "    lr = pred_lr[f\"q{q:g}\"].to_numpy(dtype=\"float64\")\n",
        "    pred_prices[f\"q{q:g}\"] = origin_close * np.exp(np.cumsum(lr))\n",
        "\n",
        "pred_prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot historical close + forecast band\n",
        "hist = prices.tail(PLOT_HISTORY_POINTS).copy()\n",
        "\n",
        "q_low = min(quantiles)\n",
        "q_high = max(quantiles)\n",
        "q_mid = sorted(quantiles)[len(quantiles) // 2]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(hist[\"time\"], hist[\"close\"], label=\"Historical close\", color=\"black\", linewidth=1.5)\n",
        "ax.axvline(origin_time, color=\"gray\", linestyle=\"--\", linewidth=1, label=\"Forecast origin\")\n",
        "\n",
        "ax.plot(pred_prices[\"time\"], pred_prices[f\"q{q_mid:g}\"], label=f\"Forecast q{q_mid:g}\", color=\"tab:blue\")\n",
        "ax.fill_between(\n",
        "    pred_prices[\"time\"],\n",
        "    pred_prices[f\"q{q_low:g}\"],\n",
        "    pred_prices[f\"q{q_high:g}\"],\n",
        "    color=\"tab:blue\",\n",
        "    alpha=0.2,\n",
        "    label=f\"Interval q{q_low:g}–q{q_high:g}\",\n",
        ")\n",
        "\n",
        "ax.set_title(f\"{SYMBOL} close price forecast ({horizon} sessions)\")\n",
        "ax.set_ylabel(\"Close\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
